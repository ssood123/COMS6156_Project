{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QvNujZSnb3-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Reshape, Concatenate, LeakyReLU\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KF6pzirCp7OU"
      },
      "outputs": [],
      "source": [
        "# Height and width refer to the size of the image\n",
        "# Channels refers to the amount of color channels (red, green, blue)\n",
        "\n",
        "image_dimensions = {'height':256, 'width':256, 'channels':3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9rnqUjjp-bp"
      },
      "outputs": [],
      "source": [
        "# Create a Classifier class\n",
        "\n",
        "class Classifier:\n",
        "    def __init__():\n",
        "        self.model = 0\n",
        "    \n",
        "    def predict(self, x):\n",
        "        return self.model.predict(x)\n",
        "    \n",
        "    def fit(self, x, y):\n",
        "        return self.model.train_on_batch(x, y)\n",
        "    \n",
        "    def get_accuracy(self, x, y):\n",
        "        return self.model.test_on_batch(x, y)\n",
        "    \n",
        "    def load(self, path):\n",
        "        self.model.load_weights(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jK643Wg4qEBj"
      },
      "outputs": [],
      "source": [
        "# Create a MesoNet class using the Classifier\n",
        "\n",
        "class Meso4(Classifier):\n",
        "    def __init__(self, learning_rate = 0.001):\n",
        "        self.model = self.init_model()\n",
        "        optimizer = Adam(lr = learning_rate)\n",
        "        self.model.compile(optimizer = optimizer,\n",
        "                           loss = 'mean_squared_error',\n",
        "                           metrics = ['accuracy'])\n",
        "    \n",
        "    def init_model(self): \n",
        "        x = Input(shape = (image_dimensions['height'],\n",
        "                           image_dimensions['width'],\n",
        "                           image_dimensions['channels']))\n",
        "        \n",
        "        x1 = Conv2D(8, (3, 3), padding='same', activation = 'relu')(x)\n",
        "        x1 = BatchNormalization()(x1)\n",
        "        x1 = MaxPooling2D(pool_size=(2, 2), padding='same')(x1)\n",
        "        \n",
        "        x2 = Conv2D(8, (5, 5), padding='same', activation = 'relu')(x1)\n",
        "        x2 = BatchNormalization()(x2)\n",
        "        x2 = MaxPooling2D(pool_size=(2, 2), padding='same')(x2)\n",
        "        \n",
        "        x3 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x2)\n",
        "        x3 = BatchNormalization()(x3)\n",
        "        x3 = MaxPooling2D(pool_size=(2, 2), padding='same')(x3)\n",
        "        \n",
        "        x4 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x3)\n",
        "        x4 = BatchNormalization()(x4)\n",
        "        x4 = MaxPooling2D(pool_size=(4, 4), padding='same')(x4)\n",
        "        \n",
        "        y = Flatten()(x4)\n",
        "        y = Dropout(0.5)(y)\n",
        "        y = Dense(16)(y)\n",
        "        y = LeakyReLU(alpha=0.1)(y)\n",
        "        y = Dropout(0.5)(y)\n",
        "        y = Dense(1, activation = 'sigmoid')(y)\n",
        "\n",
        "        return Model(inputs = x, outputs = y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDo87hlEqse5"
      },
      "outputs": [],
      "source": [
        "# Instantiate a MesoNet model with pretrained weights\n",
        "meso = Meso4()\n",
        "meso.load('/content/weights/Meso4_DF')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGmKHpwzvVCP"
      },
      "outputs": [],
      "source": [
        "# Prepare image data\n",
        "\n",
        "# Rescaling pixel values (between 1 and 255) to a range between 0 and 1\n",
        "dataGenerator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Instantiating generator to feed images through the network\n",
        "generator = dataGenerator.flow_from_directory(\n",
        "    '/content/data/',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=1,\n",
        "    class_mode='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dtc75xNsvxDJ"
      },
      "outputs": [],
      "source": [
        "# Checking class assignment\n",
        "generator.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#There are 6 categories\n",
        "realWithHighConfidence = []\n",
        "realWithMediumConfidence = []\n",
        "realWithLowConfidence = []\n",
        "fakeWithLowConfidence = []\n",
        "fakeWithMediumConfidence = []\n",
        "fakeWithHighConfidence = []\n",
        "count = 1\n",
        "for i in range(0,len(generator.labels)):\n",
        "  print(count)\n",
        "  X, y = generator.next()\n",
        "  prediction = meso.predict(X)[0][0]\n",
        "  if prediction >= 0 and prediction <= 5/30:\n",
        "    fakeWithHighConfidence.append(X)\n",
        "  elif prediction > 5/30 and prediction <= 10/30:\n",
        "    fakeWithMediumConfidence.append(X)\n",
        "  elif prediction > 10/30 and prediction <= 15/30:\n",
        "    fakeWithLowConfidence.append(X)\n",
        "  elif prediction > 15/30 and prediction <= 20/30:\n",
        "    realWithLowConfidence.append(X)\n",
        "  elif prediction > 20/30 and prediction <= 25/30:\n",
        "    realWithMediumConfidence.append(X)\n",
        "  elif prediction > 25/30 and prediction <= 30/30:\n",
        "    realWithHighConfidence.append(X)\n",
        "  count += 1\n",
        "  "
      ],
      "metadata": {
        "id": "qdihJEITqt_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "fakeHigh = (len(fakeWithHighConfidence))\n",
        "fakeMedium = (len(fakeWithMediumConfidence))\n",
        "fakeLow = (len(fakeWithLowConfidence))\n",
        "realLow = (len(realWithLowConfidence))\n",
        "realMedium = (len(realWithMediumConfidence))\n",
        "realHigh = (len(realWithHighConfidence))\n",
        "totalImages = len(generator.labels)\n",
        "\n",
        "#categories\n",
        "fakeHighPercent = str(round(fakeHigh/totalImages*100,2)) + '%'\n",
        "fakeMediumPercent = str(round(fakeMedium/totalImages*100,2))+'%'\n",
        "fakeLowPercent = str(round(fakeLow/totalImages*100,2))+'%'\n",
        "realLowPercent = str(round(realLow/totalImages*100,2))+'%'\n",
        "realMediumPercent = str(round(realMedium/totalImages*100,2))+'%'\n",
        "realHighPercent = str(round(realHigh/totalImages*100,2))+'%'\n",
        "\n",
        "table1 = [['Category','Number of images in this category','total number of images','percent of total'],\n",
        "          ['fake with high confidence',fakeHigh,len(generator.labels),fakeHighPercent],\n",
        "          ['fake with medium confidence', fakeMedium, len(generator.labels), fakeMediumPercent],\n",
        "          ['fake with low confidence', fakeLow, len(generator.labels), fakeLowPercent],\n",
        "          ['real with low confidence', realLow, len(generator.labels), realLowPercent],\n",
        "          ['real with medium confidence', realMedium, len(generator.labels), realMediumPercent],\n",
        "          ['real with high confidence', realHigh, len(generator.labels), realHighPercent]]\n",
        "print(tabulate(table1,headers='firstrow',tablefmt='fancy_grid'))\n",
        "\n",
        "\n",
        "#Predicted labels\n",
        "fakeTotal = fakeLow+fakeMedium+fakeHigh\n",
        "realTotal = realLow+realMedium+realHigh\n",
        "\n",
        "FakePercent = str(round(fakeTotal/totalImages*100,2))+'%'\n",
        "RealPercent = str(round(realTotal/totalImages*100,2))+'%'\n",
        "\n",
        "table2 = [['Predicted Label','Number of Images for this label','Total number of Images','Percent of total'],\n",
        "         ['Real', realTotal, len(generator.labels), RealPercent],\n",
        "         ['Fake', fakeTotal, len(generator.labels), FakePercent]]\n",
        "print(tabulate(table2,headers='firstrow',tablefmt='fancy_grid'))\n",
        "\n",
        "#Confidences\n",
        "lowConfidence = fakeLow + realLow\n",
        "mediumConfidence = fakeMedium + realMedium\n",
        "highConfidence = fakeHigh + realHigh\n",
        "\n",
        "lowConfidencePercent = str(round(lowConfidence/totalImages*100,2))+'%'\n",
        "mediumConfidencePercent = str(round(mediumConfidence/totalImages*100,2))+'%'\n",
        "highConfidencePercent = str(round(highConfidence/totalImages*100,2))+'%'\n",
        "\n",
        "table3 = [['Confidence', 'Number of images for this confidence interval', 'total number of images', 'percent of total'],\n",
        "          ['low confidence', lowConfidence, totalImages, lowConfidencePercent],\n",
        "          ['medium confidence', mediumConfidence, totalImages, mediumConfidencePercent],\n",
        "          ['high confidence', highConfidence, totalImages, highConfidencePercent]]\n",
        "print(tabulate(table3,headers='firstrow',tablefmt='fancy_grid'))\n",
        "\n"
      ],
      "metadata": {
        "id": "CCj2v6lRt2UK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Mesonet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}